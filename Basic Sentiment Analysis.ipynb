{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic tutorial to understand some aspects of Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Adapted from \n",
    "# https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras\n",
    "#\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(\"Sentiment.csv\")\n",
    "data = data[['text', 'sentiment']]\n",
    "data = data[data.sentiment != 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.text = data.text.apply(lambda x: x.lower())\n",
    "data.text = data.text.apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      scottwalker didnt catch the full gopdebate l...\n",
       "3      robgeorge that carly fiorina is trending  ho...\n",
       "4      danscavino gopdebate w realdonaldtrump deliv...\n",
       "5      gregabbott_tx tedcruz on my first day i will...\n",
       "6      warriorwoman91 i liked her and was happy whe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a tokenizer to transform word into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CleanUp(text):\n",
    "    tmp = text.strip().split(' ')\n",
    "    res = []\n",
    "    for i in range(len(tmp)):\n",
    "        if tmp != \"\" and tmp != \" \":\n",
    "            tmp_2 = lmtzr.lemmatize(tmp[i])\n",
    "            if tmp_2 not in stopWords:\n",
    "                res.append(tmp_2)\n",
    "    return res\n",
    "\n",
    "data.text = data.text.apply(CleanUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer to turn word into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_features, split = \" \")\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10729, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         271,   61, 1904,  604,    1,   15,   14,  207,  114,  377, 1087,\n",
       "         687,  624],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,  227,  179,    2,  439,    8,    2,   96,    1,\n",
       "          43,  605],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 1088,    1,  218,    9, 1712, 1440,  133,  584,  111,    8,\n",
       "         282,  585],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   65,  175,  265,  211,  336, 1089, 1338,  982, 1713,  126,\n",
       "           1,   22],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,  983,    7, 1165,  502,    7,  115,  127,  688,    1,   18,\n",
       "           2,  149]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(X)\n",
    "print(X.shape)\n",
    "X[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scottwalker 66\n",
      "didnt 229\n",
      "catch 6\n",
      "full 27\n",
      "gopdebate 6546\n",
      "last 611\n",
      "night 634\n",
      "scott 88\n",
      "best 145\n",
      "line 47\n"
     ]
    }
   ],
   "source": [
    "keyList = list(tokenizer.word_counts.keys())\n",
    "for i  in range(10):\n",
    "    print(keyList[i], tokenizer.word_counts[keyList[i]])\n",
    "### Should have used some kind of lemmatization and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10729 (10729, 24)\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.document_count, X.shape)\n",
    "print(tokenizer.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "\n",
    "model.add(LSTM(lstm_out, dropout = 0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding has 24 \\* 128 \\* 2000 (vocab size) number of parameters. It output 24 (max-size) * 128 (embedding dimensions) <br>\n",
    "ltsm_1 has 196 cells, for a total of 254800 parameters => each cell has 1300 parameters.\n",
    "\n",
    "Let's examine the LSTM layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 24, 128)\n",
      "(None, 196)\n"
     ]
    }
   ],
   "source": [
    "lstm = model.layers[2]\n",
    "print(lstm.input_shape)\n",
    "print(lstm.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each LSTM outputs only 1 value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7188, 24) (7188, 2) 1516\n",
      "(3541, 24) (3541, 2) 720\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape, Y_train[:, 1].sum())\n",
    "print(X_test.shape,Y_test.shape, Y_test[:,1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " - 31s - loss: 0.4464 - acc: 0.8122\n",
      "Epoch 2/7\n",
      " - 19s - loss: 0.3225 - acc: 0.8634\n",
      "Epoch 3/7\n",
      " - 19s - loss: 0.2818 - acc: 0.8826\n",
      "Epoch 4/7\n",
      " - 19s - loss: 0.2522 - acc: 0.8941\n",
      "Epoch 5/7\n",
      " - 17s - loss: 0.2282 - acc: 0.9062\n",
      "Epoch 6/7\n",
      " - 12s - loss: 0.2083 - acc: 0.9121\n",
      "Epoch 7/7\n",
      " - 11s - loss: 0.1864 - acc: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcd55a20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982133163045\n",
      "0.845789761314\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Y_train_score = model.predict_proba(X_train)\n",
    "print(metrics.roc_auc_score(Y_train[:, 1], Y_train_score[:, 1]))\n",
    "    \n",
    "Y_test_score = model.predict_proba(X_test)\n",
    "print(metrics.roc_auc_score(Y_test[:, 1], Y_test_score[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        32,  37,  99, 673, 650, 630, 155, 288, 304, 111, 678])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the output of the embedding layer (layer 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "get_1st_output = K.function([model.layers[0].input], [model.layers[1].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 24, 128)\n",
      "[[  2.64670756e-02   2.49574725e-02  -4.84679490e-02 ...,   2.40733866e-02\n",
      "   -6.80007041e-03   1.60450228e-02]\n",
      " [  2.64670756e-02   2.49574725e-02  -4.84679490e-02 ...,   2.40733866e-02\n",
      "   -6.80007041e-03   1.60450228e-02]\n",
      " [  2.64670756e-02   2.49574725e-02  -4.84679490e-02 ...,   2.40733866e-02\n",
      "   -6.80007041e-03   1.60450228e-02]\n",
      " ..., \n",
      " [  1.03278260e-04   2.66935006e-02  -1.17941119e-01 ...,  -8.81516933e-02\n",
      "   -2.38156486e-02  -8.97239055e-03]\n",
      " [  1.01476498e-02  -1.47995986e-02   5.72442962e-03 ...,   2.35218704e-02\n",
      "   -3.68115567e-02   4.38964628e-02]\n",
      " [  7.68071339e-02   4.76800241e-02  -4.70870174e-02 ...,  -6.06759861e-02\n",
      "   -6.72121868e-02   6.10079952e-02]]\n"
     ]
    }
   ],
   "source": [
    "test = get_1st_output([X_train[0].reshape(1,-1)])\n",
    "print(np.array(test).shape)\n",
    "print(test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layers turn the input of 24 values into output of shape 24x128. Notice that the first few rows of the word vectors are the same, because they correspond to the same token (\" \")."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
